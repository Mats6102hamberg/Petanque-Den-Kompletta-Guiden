/**
 * Vercel Serverless Function - AI Chatbot Backend
 * SÃ¤ker proxy fÃ¶r Gemini API
 */

// Test endpoint for API key verification
export async function testGeminiKey() {
  try {
    const apiKey = process.env.GEMINI_API_KEY;
    if (!apiKey) {
      throw new Error('GEMINI_API_KEY not found in environment variables');
    }

    const { GoogleGenerativeAI } = require('@google/generative-ai');
    const genAI = new GoogleGenerativeAI(apiKey);
    const model = genAI.getGenerativeModel({ model: "gemini-pro" });
    
    const result = await model.generateContent("Testa API-nyckel");
    const response = await result.response;
    
    return {
      status: 'success',
      response: response.text()
    };
  } catch (error) {
    return {
      status: 'error',
      message: error.message
    };
  }
}

export default async function handler(req, res) {
  // Only allow POST requests, except for the test route
  if (req.method !== 'POST' && !(req.method === 'GET' && req.query.test === 'gemini-key')) {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  // CORS headers
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'POST, GET');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'GET' && req.query.test === 'gemini-key') {
    const testResult = await testGeminiKey();
    return res.status(200).json(testResult);
  }

  try {
    const { message, conversationHistory = [] } = req.body;

    if (!message) {
      return res.status(400).json({ error: 'Message is required' });
    }

    // Get API key from environment variable
    const apiKey = process.env.GEMINI_API_KEY;
    
    if (!apiKey) {
      console.error('GEMINI_API_KEY not found in environment variables');
      return res.status(500).json({ error: 'API key not configured' });
    }

    // Import the Gemini SDK
    const { GoogleGenerativeAI } = require('@google/generative-ai');
    const genAI = new GoogleGenerativeAI(apiKey);

    // For text-only input, use the gemini-pro model
    const model = genAI.getGenerativeModel({ model: "gemini-pro" });

    // System prompt - defines chatbot personality and knowledge
    const systemPrompt = `Du Ã¤r den officiella AI-assistenten fÃ¶r 'PÃ©tanque: Den Kompletta Guiden'. Din huvuduppgift Ã¤r att hjÃ¤lpa besÃ¶kare med frÃ¥gor om boken, pÃ©tanque, och relaterade tjÃ¤nster.

DIN PERSONLIGHET OCH TON:
- Alltid vÃ¤nlig, empatisk och uppmuntrande
- AnvÃ¤nd en positiv och hjÃ¤lpsam ton i alla svar
- Var professionell men samtidigt tillgÃ¤nglig
- AnvÃ¤nd lÃ¤mpliga emojis fÃ¶r att gÃ¶ra svaren mer engagerande (men inte fÃ¶r mÃ¥nga)

VIKTIGA REGLER FÃ–R SAMSPEL MED BESÃ–KARE:
1. BÃ¶rja alltid med ett vÃ¤nligt hÃ¤lsningsfras som "Hej!" eller "VÃ¤lkommen!"
2. Var tydlig med att du representerar boken och dess fÃ¶rfattare
3. Vid frÃ¥gor du inte kan svara pÃ¥: "Det Ã¤r en bra frÃ¥ga! TyvÃ¤rr har jag inte svaret just nu. Du kan kontakta Mats direkt pÃ¥ mats@petanqueguiden.se - han hjÃ¤lper dig gÃ¤rna!"
4. Uppmuntra till kÃ¶p men var aldrig pÃ¥trÃ¤ngande
5. HÃ¥ll svar koncisa (max 3-4 meningar) sÃ¥vida inte frÃ¥gan krÃ¤ver mer detaljer
6. Vid frÃ¥gor om bokens innehÃ¥ll:
   - FrÃ¥ga alltid fÃ¶rst: "Vilken nivÃ¥ har du? Ã„r du nybÃ¶rjare, medel eller erfaren?"
   - Ge sedan specifika kapitelrekommendationer
7. Vid frÃ¥gor om priser eller kÃ¶p:
   - Var alltid tydlig med aktuella priser
   - NÃ¤mn kÃ¶palternativ (Swish, Gumroad)
   - LÃ¤nka till kop.html vid intresse
8. Vid tekniska frÃ¥gor:
   - FÃ¶rklara koncept enkelt och pedagogiskt
   - AnvÃ¤nd analogier frÃ¥n vardagen nÃ¤r det passar
   - HÃ¤nvisa till relevanta kapitel

PRODUKTINFORMATION (sammanfattning):
ðŸ“š Boken: 299 kr, 15 kapitel, 6 sprÃ¥k, livstidsÃ¥tkomst
ðŸŽ¯ FÃ¶r nybÃ¶rjare: Kapitel 1-4, Fusklapp, TrÃ¤ningsjournal
ðŸ† FÃ¶r elit: Kapitel 6,7,12,15 med avancerad taktik
ðŸ“± Appar: TrÃ¤nings-Appen (99 kr/mÃ¥n), BoulePRO (149 kr/mÃ¥n)
ðŸ›ï¸ Klubbpaket: 1,999 kr + 60 kr/mÃ¥n

KONTAKT:
- Email: mats@petanqueguiden.se
- Webbplats: petanque-den-kompletta-guiden.vercel.app`;

    // Build the chat history for Gemini
    const chatHistory = [
      {
        role: "user",
        parts: [{ text: systemPrompt }]
      },
      {
        role: "model",
        parts: [{ text: "OK, I will follow your instructions." }]
      }
    ];

    // Add the conversation history (last 6 messages)
    conversationHistory.slice(-6).forEach((msg) => {
      chatHistory.push({
        role: msg.role === 'user' ? 'user' : 'model',
        parts: [{ text: msg.content }]
      });
    });

    // Add the current user message
    chatHistory.push({
      role: "user",
      parts: [{ text: message }]
    });

    // Start a chat session
    const chat = model.startChat({
      history: chatHistory,
      generationConfig: {
        maxOutputTokens: 300,
        temperature: 0.7,
        topP: 1,
      },
    });

    // Send the message and get the response
    const result = await chat.sendMessage(message);
    const responseText = await result.response.text();

    // Return response
    return res.status(200).json({
      response: responseText
    });

  } catch (error) {
    console.error('Server error:', error);
    return res.status(500).json({ 
      error: 'Internal server error',
      message: error.message 
    });
  }
}
